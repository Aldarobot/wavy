<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Web Audio Example</title>
  <meta name="description" content="Audio basics demo for Web Audio API">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>
<body>
  <script type="text/javascript">
    // Construct an AudioContext
    let audio_cx = new (window.AudioContext || window.webkitAudioContext)();
    // Get sample rate
    console.info('Sample Rate: ' + audio_cx.sampleRate);
    // Create a root node for the audio playback in the audio graph.
    let root_node = audio_cx.createConstantSource();
    // Create a processor node on the root node.
    var proc_node = audio_cx.createScriptProcessor(1024, 1, 1 /*0*/);
    proc_node.onaudioprocess = function(proc_ev) {
        let input = proc_ev.inputBuffer.getChannelData(0);
        let output = proc_ev.outputBuffer.getChannelData(0);
        // TODO: Wake Rust code with input and output vars
        for (var i = 0; i < input.length; i++) {
            // make output equal to the same as the input
            output[i] = ((i % 128) / 128) * 2 - 1;
        }
    };
    // Build the audio graph
    root_node.connect(proc_node); // Microphone/ConstantDummy -> Processor
    proc_node.connect(audio_cx.destination); // Processor -> Speakers




    /*// Send the microphone input directly to the speakers.
    if (navigator.mediaDevices) {
        navigator.mediaDevices.getUserMedia ({audio: true})
        .then(function(stream) {
            let options = {
                mediaStreamTrack: stream.getAudioTracks()[0],
            };
            let source = new MediaStreamTrackAudioSourceNode(audioCtx, options);
            var scriptNode = audioCtx.createScriptProcessor(1024, 1, 1);
            // console.log(scriptNode.bufferSize);
            scriptNode.onaudioprocess = function(audioProcessingEvent) {
                // The input buffer is the song we loaded earlier
                var inputBuffer = audioProcessingEvent.inputBuffer;
                // The output buffer contains the samples that will be modified and played
                var outputBuffer = audioProcessingEvent.outputBuffer;
                var inputData = inputBuffer.getChannelData(0);
                var outputData = outputBuffer.getChannelData(0);
                // Process audio.
                console.log("Process");
                for (var sample = 0; sample < inputBuffer.length; sample++) {
                  // make output equal to the same as the input
                  outputData[sample] = inputData[sample];
                }
            }
            source.connect(scriptNode);
            scriptNode.connect(audioCtx.destination);
        });
    }*/
  </script>
</body>
